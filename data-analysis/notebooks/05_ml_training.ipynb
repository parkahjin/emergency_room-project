{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5fd2393c-ca45-42d1-8423-090a452c9a00",
   "metadata": {},
   "source": [
    "# 1. í•™ìŠµ ë°ì´í„° ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea61f30a-dcd0-4c5c-bb0d-478c8c988670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ğŸ¤– ë¨¸ì‹ ëŸ¬ë‹ ê¸°ë°˜ ì‘ê¸‰ì‹¤ í˜¼ì¡ë„ ì˜ˆì¸¡ ì‹œìŠ¤í…œ\n",
      "============================================================\n",
      "\n",
      "ğŸ“Š 180ì¼ì¹˜ í•™ìŠµ ë°ì´í„° ìƒì„± ì¤‘...\n",
      "âœ… í•™ìŠµ ë°ì´í„° ìƒì„± ì™„ë£Œ: 4,320ê°œ ìƒ˜í”Œ\n",
      "\n",
      "ğŸ“‹ ë°ì´í„° ìƒ˜í”Œ:\n",
      "         date  hour  day_of_week  is_weekend  is_holiday  month weather  \\\n",
      "0  2024-04-01     0            0       False       False      4       ë¹„   \n",
      "1  2024-04-01     1            0       False       False      4       ë¹„   \n",
      "2  2024-04-01     2            0       False       False      4       ë¹„   \n",
      "3  2024-04-01     3            0       False       False      4       ë¹„   \n",
      "4  2024-04-01     4            0       False       False      4       ë¹„   \n",
      "5  2024-04-01     5            0       False       False      4       ë¹„   \n",
      "6  2024-04-01     6            0       False       False      4       ë¹„   \n",
      "7  2024-04-01     7            0       False       False      4       ë¹„   \n",
      "8  2024-04-01     8            0       False       False      4       ë¹„   \n",
      "9  2024-04-01     9            0       False       False      4       ë¹„   \n",
      "\n",
      "   temperature  wait_time  \n",
      "0           20         11  \n",
      "1           20         14  \n",
      "2           20         15  \n",
      "3           20          5  \n",
      "4           20          9  \n",
      "5           20         14  \n",
      "6           20         43  \n",
      "7           20         44  \n",
      "8           20         53  \n",
      "9           20         44  \n",
      "\n",
      "ğŸ“Š ëŒ€ê¸°ì‹œê°„ í†µê³„:\n",
      "count    4320.000000\n",
      "mean       40.697222\n",
      "std        20.989848\n",
      "min         5.000000\n",
      "25%        23.000000\n",
      "50%        42.000000\n",
      "75%        56.000000\n",
      "max       114.000000\n",
      "Name: wait_time, dtype: float64\n",
      "\n",
      "ğŸŒ¤ï¸ ë‚ ì”¨ë³„ í‰ê·  ëŒ€ê¸°ì‹œê°„:\n",
      "weather\n",
      "ëˆˆ     50.2\n",
      "ë§‘ìŒ    38.8\n",
      "ë¹„     44.0\n",
      "íë¦¼    40.4\n",
      "Name: wait_time, dtype: float64\n",
      "\n",
      "ğŸ“… ìš”ì¼ë³„ í‰ê·  ëŒ€ê¸°ì‹œê°„:\n",
      "  ì›”ìš”ì¼: 42.8ë¶„\n",
      "  í™”ìš”ì¼: 38.3ë¶„\n",
      "  ìˆ˜ìš”ì¼: 36.8ë¶„\n",
      "  ëª©ìš”ì¼: 37.7ë¶„\n",
      "  ê¸ˆìš”ì¼: 38.0ë¶„\n",
      "  í† ìš”ì¼: 45.7ë¶„\n",
      "  ì¼ìš”ì¼: 45.9ë¶„\n",
      "\n",
      "â° ì‹œê°„ëŒ€ë³„ í‰ê·  ëŒ€ê¸°ì‹œê°„ (ìƒìœ„ 5ê°œ):\n",
      "  19ì‹œ: 74.3ë¶„\n",
      "  18ì‹œ: 68.1ë¶„\n",
      "  20ì‹œ: 67.3ë¶„\n",
      "  12ì‹œ: 63.5ë¶„\n",
      "  21ì‹œ: 57.5ë¶„\n",
      "\n",
      "âœ… ì…€ 1 ì™„ë£Œ! ë‹¤ìŒ ì…€ì„ ì‹¤í–‰í•˜ì„¸ìš”.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"ğŸ¤– ë¨¸ì‹ ëŸ¬ë‹ ê¸°ë°˜ ì‘ê¸‰ì‹¤ í˜¼ì¡ë„ ì˜ˆì¸¡ ì‹œìŠ¤í…œ\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ========================================\n",
    "# 1. ì‹œê°„ëŒ€ë³„ ê¸°ë³¸ íŒ¨í„´ í•¨ìˆ˜\n",
    "# ========================================\n",
    "def get_base_congestion(hour):\n",
    "    \"\"\"ì‹œê°„ëŒ€ë³„ ê¸°ë³¸ ëŒ€ê¸°ì‹œê°„ (ë¶„)\"\"\"\n",
    "    patterns = {\n",
    "        0: 15, 1: 12, 2: 10, 3: 10, 4: 12, 5: 15,\n",
    "        6: 25, 7: 30, 8: 35, 9: 40, 10: 45, 11: 50,\n",
    "        12: 55, 13: 50,\n",
    "        14: 40, 15: 35, 16: 40, 17: 45,\n",
    "        18: 60, 19: 65, 20: 60, 21: 50,\n",
    "        22: 35, 23: 25\n",
    "    }\n",
    "    return patterns.get(hour, 30)\n",
    "\n",
    "# ========================================\n",
    "# 2. í•™ìŠµìš© ì‹œê³„ì—´ ë°ì´í„° ìƒì„±\n",
    "# ========================================\n",
    "def generate_training_data(days=180):\n",
    "    \"\"\"\n",
    "    6ê°œì›”ì¹˜ í•™ìŠµ ë°ì´í„° ìƒì„±\n",
    "    ë‹¤ì–‘í•œ ë³€ìˆ˜ë¥¼ ê³ ë ¤í•œ í•©ì„± ë°ì´í„°\n",
    "    \"\"\"\n",
    "    print(f\"\\nğŸ“Š {days}ì¼ì¹˜ í•™ìŠµ ë°ì´í„° ìƒì„± ì¤‘...\")\n",
    "    \n",
    "    data = []\n",
    "    start_date = datetime(2024, 4, 1)\n",
    "    \n",
    "    for day in range(days):\n",
    "        current_date = start_date + timedelta(days=day)\n",
    "        day_of_week = current_date.weekday()\n",
    "        is_weekend = day_of_week >= 5\n",
    "        is_holiday = is_weekend\n",
    "        \n",
    "        # ë‚ ì”¨ ìƒì„±\n",
    "        weather = np.random.choice(\n",
    "            ['ë§‘ìŒ', 'íë¦¼', 'ë¹„', 'ëˆˆ'], \n",
    "            p=[0.50, 0.30, 0.15, 0.05]\n",
    "        )\n",
    "        \n",
    "        # ê¸°ì˜¨ (ê³„ì ˆ ë°˜ì˜)\n",
    "        month = current_date.month\n",
    "        base_temp_map = {\n",
    "            4: 15, 5: 20, 6: 25, 7: 28, 8: 30, 9: 25,\n",
    "            10: 20, 11: 12, 12: 5, 1: 3, 2: 5, 3: 10\n",
    "        }\n",
    "        base_temp = base_temp_map.get(month, 20)\n",
    "        temperature = base_temp + np.random.randint(-5, 6)\n",
    "        \n",
    "        # 24ì‹œê°„ ë°ì´í„°\n",
    "        for hour in range(24):\n",
    "            base_wait = get_base_congestion(hour)\n",
    "            \n",
    "            # ìš”ì¼ ì˜í–¥\n",
    "            if day_of_week == 0:\n",
    "                base_wait *= 1.15\n",
    "            elif day_of_week >= 5:\n",
    "                base_wait *= 1.20\n",
    "            \n",
    "            # ê³µíœ´ì¼ ì˜í–¥\n",
    "            if is_holiday and day_of_week < 5:\n",
    "                base_wait *= 1.25\n",
    "            \n",
    "            # ë‚ ì”¨ ì˜í–¥\n",
    "            weather_multiplier = {\n",
    "                'ë§‘ìŒ': 1.0, 'íë¦¼': 1.05, 'ë¹„': 1.15, 'ëˆˆ': 1.25\n",
    "            }\n",
    "            base_wait *= weather_multiplier[weather]\n",
    "            \n",
    "            # ê¸°ì˜¨ ì˜í–¥\n",
    "            if temperature > 32:\n",
    "                base_wait *= 1.20\n",
    "            elif temperature > 28:\n",
    "                base_wait *= 1.10\n",
    "            elif temperature < 0:\n",
    "                base_wait *= 1.25\n",
    "            elif temperature < 5:\n",
    "                base_wait *= 1.15\n",
    "            \n",
    "            # ê³„ì ˆ íŠ¹ìˆ˜ ìƒí™©\n",
    "            if month in [12, 1, 2]:\n",
    "                base_wait *= 1.10\n",
    "            elif month in [7, 8]:\n",
    "                base_wait *= 0.95\n",
    "            \n",
    "            # ëœë¤ ë…¸ì´ì¦ˆ\n",
    "            noise = np.random.randint(-10, 11)\n",
    "            final_wait_time = int(base_wait + noise)\n",
    "            final_wait_time = max(5, min(120, final_wait_time))\n",
    "            \n",
    "            data.append({\n",
    "                'date': current_date.date(),\n",
    "                'hour': hour,\n",
    "                'day_of_week': day_of_week,\n",
    "                'is_weekend': is_weekend,\n",
    "                'is_holiday': is_holiday,\n",
    "                'month': month,\n",
    "                'weather': weather,\n",
    "                'temperature': temperature,\n",
    "                'wait_time': final_wait_time\n",
    "            })\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    print(f\"âœ… í•™ìŠµ ë°ì´í„° ìƒì„± ì™„ë£Œ: {len(df):,}ê°œ ìƒ˜í”Œ\")\n",
    "    return df\n",
    "\n",
    "# ë°ì´í„° ìƒì„± ì‹¤í–‰\n",
    "df_train = generate_training_data(days=180)\n",
    "\n",
    "# ========================================\n",
    "# 3. ë°ì´í„° í™•ì¸\n",
    "# ========================================\n",
    "print(\"\\nğŸ“‹ ë°ì´í„° ìƒ˜í”Œ:\")\n",
    "print(df_train.head(10))\n",
    "\n",
    "print(\"\\nğŸ“Š ëŒ€ê¸°ì‹œê°„ í†µê³„:\")\n",
    "print(df_train['wait_time'].describe())\n",
    "\n",
    "print(\"\\nğŸŒ¤ï¸ ë‚ ì”¨ë³„ í‰ê·  ëŒ€ê¸°ì‹œê°„:\")\n",
    "print(df_train.groupby('weather')['wait_time'].mean().round(1))\n",
    "\n",
    "print(\"\\nğŸ“… ìš”ì¼ë³„ í‰ê·  ëŒ€ê¸°ì‹œê°„:\")\n",
    "days_kr = ['ì›”', 'í™”', 'ìˆ˜', 'ëª©', 'ê¸ˆ', 'í† ', 'ì¼']\n",
    "weather_by_day = df_train.groupby('day_of_week')['wait_time'].mean().round(1)\n",
    "for idx, wait in weather_by_day.items():\n",
    "    print(f\"  {days_kr[idx]}ìš”ì¼: {wait:.1f}ë¶„\")\n",
    "\n",
    "print(\"\\nâ° ì‹œê°„ëŒ€ë³„ í‰ê·  ëŒ€ê¸°ì‹œê°„ (ìƒìœ„ 5ê°œ):\")\n",
    "hourly = df_train.groupby('hour')['wait_time'].mean().sort_values(ascending=False).head(5)\n",
    "for hour, wait in hourly.items():\n",
    "    print(f\"  {hour:02d}ì‹œ: {wait:.1f}ë¶„\")\n",
    "\n",
    "print(\"\\nâœ… ì…€ 1 ì™„ë£Œ! ë‹¤ìŒ ì…€ì„ ì‹¤í–‰í•˜ì„¸ìš”.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "286e9ae2-518e-4f4a-aede-53338c41be07",
   "metadata": {},
   "source": [
    "# 2. ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ í•™ìŠµ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28ba8a16-37fb-4fbe-8bc9-b867212d64d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ğŸ¤– ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ í•™ìŠµ\n",
      "============================================================\n",
      "\n",
      "ğŸ”§ íŠ¹ì§• ì—”ì§€ë‹ˆì–´ë§...\n",
      "âœ… íŠ¹ì§• ë³€ìˆ˜: 10ê°œ\n",
      "âœ… ìƒ˜í”Œ ìˆ˜: 4,320ê°œ\n",
      "\n",
      "ğŸ“š í•™ìŠµ ë°ì´í„°: 3,456ê°œ\n",
      "ğŸ“– í…ŒìŠ¤íŠ¸ ë°ì´í„°: 864ê°œ\n",
      "\n",
      "ğŸŒ² Random Forest ëª¨ë¸ í•™ìŠµ ì¤‘...\n",
      "âœ… ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!\n",
      "\n",
      "ğŸ“Š ëª¨ë¸ í‰ê°€:\n",
      "\n",
      "[í•™ìŠµ ë°ì´í„° ì„±ëŠ¥]\n",
      "  MAE (í‰ê·  ì ˆëŒ€ ì˜¤ì°¨): 3.52ë¶„\n",
      "  RMSE (í‰ê·  ì œê³±ê·¼ ì˜¤ì°¨): 4.24ë¶„\n",
      "  RÂ² (ê²°ì •ê³„ìˆ˜): 0.959\n",
      "  ì •í™•ë„: 91.3%\n",
      "\n",
      "[í…ŒìŠ¤íŠ¸ ë°ì´í„° ì„±ëŠ¥]\n",
      "  MAE (í‰ê·  ì ˆëŒ€ ì˜¤ì°¨): 5.66ë¶„\n",
      "  RMSE (í‰ê·  ì œê³±ê·¼ ì˜¤ì°¨): 6.70ë¶„\n",
      "  RÂ² (ê²°ì •ê³„ìˆ˜): 0.904\n",
      "  ì •í™•ë„: 86.3%\n",
      "\n",
      "ğŸ‰ ëª©í‘œ ë‹¬ì„±! ì˜ˆì¸¡ ì •í™•ë„ 86.3% (ëª©í‘œ: 85% ì´ìƒ)\n",
      "\n",
      "ğŸ¯ íŠ¹ì§• ì¤‘ìš”ë„ (Top 5):\n",
      "  hour                : 0.881\n",
      "  temperature         : 0.032\n",
      "  day_of_week         : 0.028\n",
      "  weather_ëˆˆ           : 0.015\n",
      "  month               : 0.012\n",
      "\n",
      "ğŸ’¾ ëª¨ë¸ ì €ì¥ ì™„ë£Œ:\n",
      "  - D:/emergency_room/data-analysis/models/congestion_model.pkl\n",
      "  - D:/emergency_room/data-analysis/models/feature_columns.pkl\n",
      "\n",
      "âœ… ëª¨ë¸ í•™ìŠµ ì™„ë£Œ! ë‹¤ìŒ ì…€ì„ ì‹¤í–‰í•˜ì„¸ìš”.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ğŸ¤– ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ í•™ìŠµ\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ========================================\n",
    "# 1. íŠ¹ì§• ì—”ì§€ë‹ˆì–´ë§\n",
    "# ========================================\n",
    "print(\"\\nğŸ”§ íŠ¹ì§• ì—”ì§€ë‹ˆì–´ë§...\")\n",
    "\n",
    "# ë‚ ì”¨ë¥¼ ìˆ«ìë¡œ ë³€í™˜ (ì›-í•« ì¸ì½”ë”©)\n",
    "df_encoded = pd.get_dummies(df_train, columns=['weather'], prefix='weather')\n",
    "\n",
    "# íŠ¹ì§•ê³¼ íƒ€ê²Ÿ ë¶„ë¦¬\n",
    "feature_columns = [\n",
    "    'hour', 'day_of_week', 'is_weekend', 'is_holiday', \n",
    "    'month', 'temperature',\n",
    "    'weather_ë§‘ìŒ', 'weather_ëˆˆ', 'weather_ë¹„', 'weather_íë¦¼'\n",
    "]\n",
    "\n",
    "X = df_encoded[feature_columns]\n",
    "y = df_encoded['wait_time']\n",
    "\n",
    "print(f\"âœ… íŠ¹ì§• ë³€ìˆ˜: {len(feature_columns)}ê°œ\")\n",
    "print(f\"âœ… ìƒ˜í”Œ ìˆ˜: {len(X):,}ê°œ\")\n",
    "\n",
    "# ========================================\n",
    "# 2. í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¶„í• \n",
    "# ========================================\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"\\nğŸ“š í•™ìŠµ ë°ì´í„°: {len(X_train):,}ê°œ\")\n",
    "print(f\"ğŸ“– í…ŒìŠ¤íŠ¸ ë°ì´í„°: {len(X_test):,}ê°œ\")\n",
    "\n",
    "# ========================================\n",
    "# 3. Random Forest ëª¨ë¸ í•™ìŠµ\n",
    "# ========================================\n",
    "print(\"\\nğŸŒ² Random Forest ëª¨ë¸ í•™ìŠµ ì¤‘...\")\n",
    "\n",
    "model = RandomForestRegressor(\n",
    "    n_estimators=100,\n",
    "    max_depth=15,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "print(\"âœ… ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!\")\n",
    "\n",
    "# ========================================\n",
    "# 4. ëª¨ë¸ í‰ê°€\n",
    "# ========================================\n",
    "print(\"\\nğŸ“Š ëª¨ë¸ í‰ê°€:\")\n",
    "\n",
    "y_pred_train = model.predict(X_train)\n",
    "y_pred_test = model.predict(X_test)\n",
    "\n",
    "mae_train = mean_absolute_error(y_train, y_pred_train)\n",
    "mae_test = mean_absolute_error(y_test, y_pred_test)\n",
    "\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "\n",
    "r2_train = r2_score(y_train, y_pred_train)\n",
    "r2_test = r2_score(y_test, y_pred_test)\n",
    "\n",
    "accuracy_train = (1 - mae_train/y_train.mean()) * 100\n",
    "accuracy_test = (1 - mae_test/y_test.mean()) * 100\n",
    "\n",
    "print(f\"\\n[í•™ìŠµ ë°ì´í„° ì„±ëŠ¥]\")\n",
    "print(f\"  MAE (í‰ê·  ì ˆëŒ€ ì˜¤ì°¨): {mae_train:.2f}ë¶„\")\n",
    "print(f\"  RMSE (í‰ê·  ì œê³±ê·¼ ì˜¤ì°¨): {rmse_train:.2f}ë¶„\")\n",
    "print(f\"  RÂ² (ê²°ì •ê³„ìˆ˜): {r2_train:.3f}\")\n",
    "print(f\"  ì •í™•ë„: {accuracy_train:.1f}%\")\n",
    "\n",
    "print(f\"\\n[í…ŒìŠ¤íŠ¸ ë°ì´í„° ì„±ëŠ¥]\")\n",
    "print(f\"  MAE (í‰ê·  ì ˆëŒ€ ì˜¤ì°¨): {mae_test:.2f}ë¶„\")\n",
    "print(f\"  RMSE (í‰ê·  ì œê³±ê·¼ ì˜¤ì°¨): {rmse_test:.2f}ë¶„\")\n",
    "print(f\"  RÂ² (ê²°ì •ê³„ìˆ˜): {r2_test:.3f}\")\n",
    "print(f\"  ì •í™•ë„: {accuracy_test:.1f}%\")\n",
    "\n",
    "if accuracy_test >= 85:\n",
    "    print(f\"\\nğŸ‰ ëª©í‘œ ë‹¬ì„±! ì˜ˆì¸¡ ì •í™•ë„ {accuracy_test:.1f}% (ëª©í‘œ: 85% ì´ìƒ)\")\n",
    "else:\n",
    "    print(f\"\\nâš ï¸ ëª©í‘œ ë¯¸ë‹¬ì„±: {accuracy_test:.1f}% (ëª©í‘œ: 85%)\")\n",
    "\n",
    "# ========================================\n",
    "# 5. íŠ¹ì§• ì¤‘ìš”ë„ ë¶„ì„\n",
    "# ========================================\n",
    "print(\"\\nğŸ¯ íŠ¹ì§• ì¤‘ìš”ë„ (Top 5):\")\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': feature_columns,\n",
    "    'importance': model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "for idx, row in feature_importance.head(5).iterrows():\n",
    "    print(f\"  {row['feature']:20s}: {row['importance']:.3f}\")\n",
    "\n",
    "# ========================================\n",
    "# 6. ëª¨ë¸ ì €ì¥\n",
    "# ========================================\n",
    "models_dir = 'D:/emergency_room/data-analysis/models'\n",
    "os.makedirs(models_dir, exist_ok=True)\n",
    "\n",
    "model_path = f'{models_dir}/congestion_model.pkl'\n",
    "features_path = f'{models_dir}/feature_columns.pkl'\n",
    "\n",
    "with open(model_path, 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "with open(features_path, 'wb') as f:\n",
    "    pickle.dump(feature_columns, f)\n",
    "\n",
    "print(f\"\\nğŸ’¾ ëª¨ë¸ ì €ì¥ ì™„ë£Œ:\")\n",
    "print(f\"  - {model_path}\")\n",
    "print(f\"  - {features_path}\")\n",
    "\n",
    "print(\"\\nâœ… ëª¨ë¸ í•™ìŠµ ì™„ë£Œ! ë‹¤ìŒ ì…€ì„ ì‹¤í–‰í•˜ì„¸ìš”.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd021f60-07ae-4bd9-a7f1-4360ec5772a5",
   "metadata": {},
   "source": [
    "# 3. 46ê°œ ë³‘ì› ì˜ˆì¸¡ ë°ì´í„° ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd84cee3-1344-46d4-8b49-87a4a9b77395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ğŸ¥ 46ê°œ ë³‘ì› Ã— 24ì‹œê°„ ì˜ˆì¸¡ ë°ì´í„° ìƒì„±\n",
      "============================================================\n",
      "\n",
      "âœ… ë³‘ì› ë°ì´í„° ë¡œë“œ: 46ê°œ ë³‘ì›\n",
      "\n",
      "ğŸ”® ì˜ˆì¸¡ ë°ì´í„° ìƒì„± ì¤‘...\n",
      "âœ… ì˜ˆì¸¡ ë°ì´í„° ìƒì„± ì™„ë£Œ: 1,104ê°œ\n",
      "\n",
      "ğŸ“Š ì˜ˆì¸¡ ê²°ê³¼ í†µê³„:\n",
      "congestion_level\n",
      "ë³´í†µ    642\n",
      "ì—¬ìœ     383\n",
      "í˜¼ì¡     79\n",
      "Name: count, dtype: int64\n",
      "\n",
      "â° ì‹œê°„ëŒ€ë³„ í‰ê·  ì˜ˆì¸¡ ëŒ€ê¸°ì‹œê°„:\n",
      "  06ì‹œ: 24.0ë¶„\n",
      "  09ì‹œ: 38.0ë¶„\n",
      "  12ì‹œ: 51.4ë¶„\n",
      "  15ì‹œ: 38.0ë¶„\n",
      "  18ì‹œ: 60.9ë¶„\n",
      "  21ì‹œ: 46.0ë¶„\n",
      "\n",
      "ğŸ’¾ CSV ì €ì¥ ì™„ë£Œ: D:/emergency_room/data-analysis/data/simulated/ml_emergency_predictions.csv\n",
      "\n",
      "âœ… ì˜ˆì¸¡ ë°ì´í„° ìƒì„± ì™„ë£Œ! ë‹¤ìŒ ì…€ì—ì„œ MySQLì— ì‚½ì…í•©ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ğŸ¥ 46ê°œ ë³‘ì› Ã— 24ì‹œê°„ ì˜ˆì¸¡ ë°ì´í„° ìƒì„±\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ========================================\n",
    "# 1. ë³‘ì› ë°ì´í„° ë¡œë“œ\n",
    "# ========================================\n",
    "hospitals_path = 'D:/emergency_room/data-analysis/data/raw/busan_hospitals_static.csv'\n",
    "hospitals = pd.read_csv(hospitals_path)\n",
    "\n",
    "print(f\"\\nâœ… ë³‘ì› ë°ì´í„° ë¡œë“œ: {len(hospitals)}ê°œ ë³‘ì›\")\n",
    "\n",
    "# ========================================\n",
    "# 2. ë³‘ì› íŠ¹ì„±ë³„ ì¡°ì • í•¨ìˆ˜\n",
    "# ========================================\n",
    "def adjust_by_hospital(base_time, emergency_level, beds_total):\n",
    "    \"\"\"ë³‘ì› íŠ¹ì„±ì„ ë°˜ì˜í•œ ëŒ€ê¸°ì‹œê°„ ì¡°ì •\"\"\"\n",
    "    level_multiplier = {\n",
    "        'ê¶Œì—­ì‘ê¸‰ì˜ë£Œì„¼í„°': 1.3,\n",
    "        'ì§€ì—­ì‘ê¸‰ì˜ë£Œì„¼í„°': 1.1,\n",
    "        'ì§€ì—­ì‘ê¸‰ì˜ë£Œê¸°ê´€': 0.9,\n",
    "        'ì‘ê¸‰ì˜ë£Œê¸°ê´€': 0.8\n",
    "    }\n",
    "    \n",
    "    multiplier = level_multiplier.get(emergency_level, 1.0)\n",
    "    adjusted = base_time * multiplier\n",
    "    \n",
    "    if pd.notna(beds_total):\n",
    "        if beds_total > 500:\n",
    "            adjusted *= 0.85\n",
    "        elif beds_total > 300:\n",
    "            adjusted *= 0.95\n",
    "        elif beds_total < 200:\n",
    "            adjusted *= 1.1\n",
    "    \n",
    "    return int(adjusted)\n",
    "\n",
    "def get_congestion_info(wait_time):\n",
    "    \"\"\"ëŒ€ê¸°ì‹œê°„ â†’ í˜¼ì¡ë„ ë ˆë²¨ & ìƒ‰ìƒ\"\"\"\n",
    "    if wait_time < 30:\n",
    "        return 'ì—¬ìœ ', 'green'\n",
    "    elif wait_time < 60:\n",
    "        return 'ë³´í†µ', 'yellow'\n",
    "    else:\n",
    "        return 'í˜¼ì¡', 'red'\n",
    "\n",
    "# ========================================\n",
    "# 3. ì˜ˆì¸¡ ë°ì´í„° ìƒì„±\n",
    "# ========================================\n",
    "print(\"\\nğŸ”® ì˜ˆì¸¡ ë°ì´í„° ìƒì„± ì¤‘...\")\n",
    "\n",
    "# í˜„ì¬ ë‚ ì§œ ì •ë³´\n",
    "now = datetime.now()\n",
    "current_day = now.weekday()\n",
    "is_weekend = current_day >= 5\n",
    "current_month = now.month\n",
    "\n",
    "# í˜„ì¬ ë‚ ì”¨ (ê°€ì •)\n",
    "current_weather = 'ë§‘ìŒ'\n",
    "current_temp = 20\n",
    "\n",
    "predictions = []\n",
    "\n",
    "for _, hospital in hospitals.iterrows():\n",
    "    for hour in range(24):\n",
    "        # ì˜ˆì¸¡ìš© íŠ¹ì§• ë°ì´í„° ìƒì„±\n",
    "        X_pred_dict = {\n",
    "            'hour': hour,\n",
    "            'day_of_week': current_day,\n",
    "            'is_weekend': is_weekend,\n",
    "            'is_holiday': False,\n",
    "            'month': current_month,\n",
    "            'temperature': current_temp,\n",
    "            'weather_ë§‘ìŒ': 1 if current_weather == 'ë§‘ìŒ' else 0,\n",
    "            'weather_ëˆˆ': 1 if current_weather == 'ëˆˆ' else 0,\n",
    "            'weather_ë¹„': 1 if current_weather == 'ë¹„' else 0,\n",
    "            'weather_íë¦¼': 1 if current_weather == 'íë¦¼' else 0,\n",
    "        }\n",
    "        \n",
    "        X_pred = pd.DataFrame([X_pred_dict])[feature_columns]\n",
    "        \n",
    "        # ëª¨ë¸ ì˜ˆì¸¡\n",
    "        predicted_time = int(model.predict(X_pred)[0])\n",
    "        \n",
    "        # ë³‘ì› íŠ¹ì„± ë°˜ì˜\n",
    "        adjusted_time = adjust_by_hospital(\n",
    "            predicted_time,\n",
    "            hospital['emergency_level'],\n",
    "            hospital['beds_total']\n",
    "        )\n",
    "        \n",
    "        # í˜¼ì¡ë„ ë ˆë²¨ ê²°ì •\n",
    "        level, color = get_congestion_info(adjusted_time)\n",
    "        \n",
    "        predictions.append({\n",
    "            'hospital_id': hospital['id'],\n",
    "            'prediction_hour': hour,\n",
    "            'predicted_wait_time': adjusted_time,\n",
    "            'congestion_level': level,\n",
    "            'congestion_color': color\n",
    "        })\n",
    "\n",
    "df_predictions = pd.DataFrame(predictions)\n",
    "\n",
    "print(f\"âœ… ì˜ˆì¸¡ ë°ì´í„° ìƒì„± ì™„ë£Œ: {len(df_predictions):,}ê°œ\")\n",
    "\n",
    "# ========================================\n",
    "# 4. í†µê³„ í™•ì¸\n",
    "# ========================================\n",
    "print(\"\\nğŸ“Š ì˜ˆì¸¡ ê²°ê³¼ í†µê³„:\")\n",
    "print(df_predictions['congestion_level'].value_counts())\n",
    "\n",
    "print(\"\\nâ° ì‹œê°„ëŒ€ë³„ í‰ê·  ì˜ˆì¸¡ ëŒ€ê¸°ì‹œê°„:\")\n",
    "hourly_pred = df_predictions.groupby('prediction_hour')['predicted_wait_time'].mean()\n",
    "for hour in [6, 9, 12, 15, 18, 21]:\n",
    "    print(f\"  {hour:02d}ì‹œ: {hourly_pred[hour]:.1f}ë¶„\")\n",
    "\n",
    "# ========================================\n",
    "# 5. CSV ì €ì¥\n",
    "# ========================================\n",
    "output_path = 'D:/emergency_room/data-analysis/data/simulated/ml_emergency_predictions.csv'\n",
    "df_predictions.to_csv(output_path, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(f\"\\nğŸ’¾ CSV ì €ì¥ ì™„ë£Œ: {output_path}\")\n",
    "print(\"\\nâœ… ì˜ˆì¸¡ ë°ì´í„° ìƒì„± ì™„ë£Œ! ë‹¤ìŒ ì…€ì—ì„œ MySQLì— ì‚½ì…í•©ë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e91534-f8a6-4911-bdf7-78aa10d71869",
   "metadata": {},
   "source": [
    "# 4. MySQLì— ì‚½ì…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "556c4f45-a038-4694-8c16-f55fc9ff53b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ğŸ’¾ MySQLì— ì˜ˆì¸¡ ë°ì´í„° ì‚½ì…\n",
      "============================================================\n",
      "\n",
      "âœ… CSV ë¡œë“œ ì™„ë£Œ: 1104ê°œ ë°ì´í„°\n",
      "âœ… MySQL ì—°ê²° ì„±ê³µ!\n",
      "âœ… ê¸°ì¡´ ë°ì´í„° ì‚­ì œ ì™„ë£Œ\n",
      "\n",
      "ğŸ“¥ ë°ì´í„° ì‚½ì… ì¤‘...\n",
      "âœ… 1104ê°œ ë°ì´í„° ì‚½ì… ì™„ë£Œ!\n",
      "\n",
      "ğŸ“Š í…Œì´ë¸” ì´ ë ˆì½”ë“œ ìˆ˜: 1104\n",
      "\n",
      "í˜¼ì¡ë„ ë¶„í¬:\n",
      "  ì—¬ìœ : 383ê°œ\n",
      "  ë³´í†µ: 642ê°œ\n",
      "  í˜¼ì¡: 79ê°œ\n",
      "\n",
      "âœ… MySQL ì‚½ì… ì™„ë£Œ!\n",
      "\n",
      "MySQL ì—°ê²° ì¢…ë£Œ\n"
     ]
    }
   ],
   "source": [
    "import mysql.connector\n",
    "from mysql.connector import Error\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ğŸ’¾ MySQLì— ì˜ˆì¸¡ ë°ì´í„° ì‚½ì…\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ========================================\n",
    "# 1. CSV ë¡œë“œ\n",
    "# ========================================\n",
    "csv_path = 'D:/emergency_room/data-analysis/data/simulated/ml_emergency_predictions.csv'\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "print(f\"\\nâœ… CSV ë¡œë“œ ì™„ë£Œ: {len(df)}ê°œ ë°ì´í„°\")\n",
    "\n",
    "# ========================================\n",
    "# 2. MySQL ì—°ê²°\n",
    "# ========================================\n",
    "try:\n",
    "    connection = mysql.connector.connect(\n",
    "        host='localhost',\n",
    "        port=3306,\n",
    "        database='emergency_room',\n",
    "        user='root',\n",
    "        password='1234'  # â† ğŸ”‘ ë¹„ë°€ë²ˆí˜¸!\n",
    "    )\n",
    "    \n",
    "    if connection.is_connected():\n",
    "        print(f\"âœ… MySQL ì—°ê²° ì„±ê³µ!\")\n",
    "        \n",
    "        cursor = connection.cursor()\n",
    "        \n",
    "        # ========================================\n",
    "        # 3. ê¸°ì¡´ ë°ì´í„° ì‚­ì œ\n",
    "        # ========================================\n",
    "        cursor.execute(\"DELETE FROM emergency_predictions\")\n",
    "        connection.commit()\n",
    "        print(f\"âœ… ê¸°ì¡´ ë°ì´í„° ì‚­ì œ ì™„ë£Œ\")\n",
    "        \n",
    "        # ========================================\n",
    "        # 4. ìƒˆ ë°ì´í„° ì‚½ì…\n",
    "        # ========================================\n",
    "        insert_query = \"\"\"\n",
    "        INSERT INTO emergency_predictions \n",
    "        (hospital_id, prediction_hour, predicted_wait_time, congestion_level, congestion_color)\n",
    "        VALUES (%s, %s, %s, %s, %s)\n",
    "        \"\"\"\n",
    "        \n",
    "        data_list = df.values.tolist()\n",
    "        \n",
    "        print(f\"\\nğŸ“¥ ë°ì´í„° ì‚½ì… ì¤‘...\")\n",
    "        cursor.executemany(insert_query, data_list)\n",
    "        connection.commit()\n",
    "        \n",
    "        print(f\"âœ… {cursor.rowcount}ê°œ ë°ì´í„° ì‚½ì… ì™„ë£Œ!\")\n",
    "        \n",
    "        # ========================================\n",
    "        # 5. í™•ì¸\n",
    "        # ========================================\n",
    "        cursor.execute(\"SELECT COUNT(*) FROM emergency_predictions\")\n",
    "        total = cursor.fetchone()[0]\n",
    "        print(f\"\\nğŸ“Š í…Œì´ë¸” ì´ ë ˆì½”ë“œ ìˆ˜: {total}\")\n",
    "        \n",
    "        cursor.execute(\"\"\"\n",
    "            SELECT congestion_level, COUNT(*) \n",
    "            FROM emergency_predictions \n",
    "            GROUP BY congestion_level\n",
    "        \"\"\")\n",
    "        \n",
    "        print(f\"\\ní˜¼ì¡ë„ ë¶„í¬:\")\n",
    "        for row in cursor.fetchall():\n",
    "            print(f\"  {row[0]}: {row[1]}ê°œ\")\n",
    "        \n",
    "        cursor.close()\n",
    "        print(f\"\\nâœ… MySQL ì‚½ì… ì™„ë£Œ!\")\n",
    "\n",
    "except Error as e:\n",
    "    print(f\"âŒ MySQL ì˜¤ë¥˜: {e}\")\n",
    "\n",
    "finally:\n",
    "    if connection.is_connected():\n",
    "        connection.close()\n",
    "        print(f\"\\nMySQL ì—°ê²° ì¢…ë£Œ\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
